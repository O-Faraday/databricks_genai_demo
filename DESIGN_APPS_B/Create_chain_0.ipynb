{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c1d17aa-3555-4040-8c4d-aeda4ac5741a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple chain \n",
    "\n",
    "Here is a list of the crucial libraries that provides framework for building a langage model pipeline, allready integrated in Databricks. \n",
    "Let's describe a few of them :\n",
    "\n",
    "1. **LangChain** is a library that allows you to integrate pre-trained models or other open-source libraries into your workflow. The reason to choose LangChain is its flexibility and compatibility with large language models. You can create powerfull and complex workflows with **Langgraph**. Currently, one of the most, if not the most, used genAI workflow of the market. Thati is the one I will use in this notebook.\n",
    "\n",
    "2. **DSPy** automates prompt tuning by translating user-defined natural language signatures into complete instructions and few-shot examples. Very usefull if you want to optimize your prompt automatically\n",
    "\n",
    "3. **Hugging Face Transformers**: This is a state-of-the-art library for Natural Language Processing (NLP). It provides thousands of pre-trained models to perform tasks on texts such as classification, information extraction, summarization, translation, text generation, etc. The reason to choose this library is the wide variety of pre-trained models it offers, its active community, and its seamless integration with PyTorch and TensorFlow. Many of the popular NLP models work best on GPU hardware, so you might get the best performance using recent GPU hardware unless you use a model specifically optimized for use on CPUs.\n",
    "\n",
    "The choice of these libraries depends on the specific requirements of your project. They all provide different functionalities that can be useful in different stages of a language model pipeline, from data preprocessing to model training and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6bbbde-eb06-4b44-a3b0-c552fe5aa4c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Deploy Your LLM Chatbots with Mosaic AI Agent Framework\n",
    "\n",
    "In this tutorial, you will learn how to build your own Chatbot Assistant to help your customers answer questions about Databricks. \n",
    "To use this first notebook, make sure you have done the prerequisites :\n",
    "- Create a scope with you OPENAI_API_KEY as secret, due to the limitations of this free version of Databricks. We will be limited in the number of serving models at our disposal. We 'll use gpt-4o-mini for chat.\n",
    "- Create the llm endpoint,  due to the limitations of this free version of Databricks. We will be limited in the number of serving models at our disposal. We 'll use gpt-4o-mini for chat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48335f97-c075-4809-806e-cbb0bb531079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the librairies   and the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2389345e-9cb9-4814-a638-ec7313cfcd31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet databricks-langchain==0.6.0 mlflow[databricks]==3.1.0  langchain==0.3.27 langchain_core==0.3.74\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6903647-7356-4211-b9e4-0a64bc305f51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this config, the settings of the experiments will be set.\n",
    "\n",
    "One experiment is set in MLFlow with the name /Users/oliver@mlops-media.com/langchain_chain_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58216a04-a4ff-44c1-89ab-c31b626f9c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../_config/config_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c9243c-f5a8-46a0-8085-51e456819681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1- Build the chain \n",
    "First we will use a simple chain with a prompt, llm, output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d60085d-0684-4086-b256-59a77672b755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "prepare the chain config\n",
    "- First, we will define the model endpoint llm_model_serving_endpoint_name\n",
    "- And then the template with the system instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c2a0d22-2cdf-4226-b6f9-2fbfbc727139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": \"chat_gpt_4o_mini\",  # the foundation model we want to use\n",
    "    \"llm_system_message_template\": \"You are an databricks pyspark developper that answer the user's questions.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf889f6d-c32b-4256-8e21-4d7b9e7dd50f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 1-1 MLFlow integration \n",
    "\n",
    "The workflow library is langchain.\n",
    "\n",
    "It's the model flavor, used to specify mlflow which integrated library is used.\n",
    "\n",
    "An MLflow flavor is a standardized way to package, save, and load machine learning models in MLflow. \n",
    "\n",
    "It defines the interface and conventions for how different types of models can be stored and deployed consistently within the MLflow ecosystem.\n",
    "\n",
    "OpenAI, Langchain, Llama_index, HuggingFace, SBert, DSPy\n",
    "([built_in flavors](https://mlflow.org/docs/2.21.3/model/#models_built-in-model-flavors))\n",
    "\n",
    "MLflow autolog is a feature that automatically tracks metrics, parameters, artifacts, and models during machine learning experiments without requiring manual logging code.\n",
    "\n",
    "mlflow.models.ModelConfig, this feature will log the model config in the model package\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f867c9f-ed41-4781-a8db-31c11b945f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Enable MLflow Tracing\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "## Load the chain's configuration\n",
    "model_config = mlflow.models.ModelConfig(development_config=chain_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3d475f4-ecb1-4d30-aece-4552bf06fbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1-2 Chain creation\n",
    "\n",
    "Creation of the chain : \n",
    "- prompt / chat message = system instructions + user query\n",
    "- ChatDatabricks is chat langchain integration. Fully integrated in databricks, advanced properties, that improves performance, automates authentification, access to serving endpoints ..\n",
    "- Finishing with a parser to present the final answer in a comprehensive format for the user.\n",
    "\n",
    "Chain : the pipe is there to create a pipeline of sequential operation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee0e3a6-7104-4ab0-a426-49d33fdddc34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1- Chat message creation\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [  \n",
    "        (\"system\", model_config.get(\"llm_system_message_template\")), # Contains the instructions from the configuration\n",
    "        (\"user\", \"{question}\") #user's questions\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2- Integration of the model endpoint as the chat model\n",
    "model = ChatDatabricks(\n",
    "    endpoint=model_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.7, \"max_tokens\": 500}\n",
    ")\n",
    "\n",
    "# gaather the components in the chain\n",
    "chain = prompt | model | StrOutputParser() # 3- Post-processing of the model to extract the part of the answer for the user\n",
    "\n",
    "# Test of the chain\n",
    "query = 'How to start a Databricks cluster?'\n",
    "answer = chain.invoke({'question':query})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4add797f-ac5b-4273-8e1e-65f2fd1dbcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.extra_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae01c6c5-11fd-499d-8291-f3211ac281cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Observation : \n",
    "On the left menu, go to experiment, choose the \"langchain_chain_demo\" one.\n",
    "\n",
    "In this experiment, we can have a first glance at MLflow traces feature.\n",
    "Each row correspond to an invocation of the model, you can read  \n",
    "- the user query or request\n",
    "- the model response\n",
    "- the total number of tokens\n",
    "- the duration of the workflow,\n",
    "- the time of the request,\n",
    "- the status OK, ERROR .. of the workflow.\n",
    "\n",
    "If you click on the column button, you can choose the params you want to display, such as the user..\n",
    "\n",
    "\n",
    "Then click on the request col to get more infos about the workflow. \n",
    "You get some on the details and timeline, traces of the workflow.\n",
    "Each task of the workflow, prompt, chat and ouput parser is described.\n",
    "\n",
    "If you show exection time line the duration of each task appears, of course in case of bottleneck, that can be very helpfull.\n",
    "In our case, no surprise, the call the openai api is the longest task of the workflow here.\n",
    "For each step of the workflow, the input/output are registered, you can add whatever attributes you choose, in the case of chat databricks some are already integrated.\n",
    "Event is the column where you can find info about issue that can happen, very usefull !!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e77395-1015-4ca5-ad15-27da496e6d64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2- Chain log and deploy\n",
    "\n",
    "mlflow.langchain.log_model Log a LangChain model as an MLflow artifact for the current run.\n",
    "\n",
    "A LangChain model, which could be a Chain, Agent, or retriever or a path containing the LangChain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504d5084-cd77-48f1-830c-ad36b6669205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-1 Model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4239f94-a5c3-4453-aa0b-7dfe6a868724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "# Define the input\n",
    "input_example = {\"question\": \"How to start a Databricks cluster?\"}\n",
    "\n",
    "#  infer signature from an input example and the answer. Needed to create the model package\n",
    "signature = infer_signature(input_example, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "043e9bae-dd9f-44aa-bd88-4ea1774b97c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-2 Create a package model\n",
    "As we use the mlflow log_model method, the model will be stored as a package.\n",
    "\n",
    "Ready for deploy on any prod environment (prod, docker, ..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "285fd472-821a-45e3-acf7-8c52aa5fe3bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    logged_model = mlflow.langchain.log_model(\n",
    "        lc_model=chain,\n",
    "        name=\"simple_chain\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        params=model.extra_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc4021d-e9b1-4c74-b816-090000668560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### OBSERVATION : \n",
    "Click on the link to go where the model is logged\n",
    "- overview : general infos about the model, no metrics because none has been defined already, the parameters are stored.\n",
    "- artifact : the package is a generic one, if the model was well logged, you can install with this package on every environment. For example : requirements.txt contains the libraries used for the package...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93baae72-d100-4351-92c4-b7b8e3b3faf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b733567-4372-4dcb-b589-1d16bb39a9f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-3 load the model\n",
    "This functionnality allows us to register the model in UC where you can apply the gouver and share the models with co-dev.\n",
    "You can find infos in the mlflow overview table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5316fe-678d-4b1a-8c89-ba6a840e3e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the chain locally\n",
    "# get logged model infos, the uri \n",
    "model_uri = logged_model.model_uri\n",
    "chain = mlflow.pyfunc.load_model(model_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e9f9033-337b-4a93-b7fc-e9cc07599d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09cc291d-e336-471d-955f-3f96311586d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chain.predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927ef0dc-af1c-4e89-adb9-13fd4d32f460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-4 Register the model on UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "156d062d-5163-43fa-b9cf-bda70b6076cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS DEMO; \n",
    "USE CATALOG DEMO;\n",
    "CREATE SCHEMA IF NOT EXISTS DEMO; \n",
    "USE SCHEMA DEMO;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24a2d2e7-7313-4316-9bd1-1c4c5511e62e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name=\"demo\"\n",
    "schema_name=\"demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c358a4c3-4115-4ffe-ae51-fc5a076496bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"simple_chain\"\n",
    "uc_registered_model = mlflow.register_model(model_uri=model_uri, name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdf8bbb5-a8ea-441c-95b5-36b7d483cc87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can check the model in the UC catalog.\n",
    "- overview : we have first infos about the registered model, can create any tags, decriptions or aliases needed\n",
    "- lineage : infos about the notebook used to create the workflow\n",
    "- artifact : the package of the model\n",
    "- trace : traces of the model calls \n",
    "\n",
    "You also get access through the UI : \n",
    "- overview : we have first infos about the  model, can create any tags, decriptions or aliases needed. \n",
    "- description : infos about the model, date of creation, model_id.\n",
    "- permissions : you can grant or revoke privileges to the user.\n",
    "Yu can also serve the model as an endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662f71fb-85bc-48d5-8191-b7d6f131a826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an endpoint for the model\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Configuration\n",
    "mlflow_client = get_deploy_client(\"databricks\")\n",
    "endpoints = mlflow_client.list_endpoints()\n",
    "print(\"list_endpoints : \", len(endpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8909a017-1d8f-454e-b7ac-30a13e7e640d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_client.delete_endpoint(endpoint=\"text_embedding_3_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fab4bdd-2ea3-48ba-876a-46495990cb61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-4 Create the endpoint for the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3bfd1d8-8a7f-4e9b-a3e3-18e36f502e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "endpoint_name = \"simple_chain\"\n",
    "model_name = f\"{catalog_name}.{schema_name}.{endpoint_name}\"\n",
    "model_version = \"1\"  # Version of the model\n",
    "\n",
    "# Create the endpoint\n",
    "endpoint = mlflow_client.create_endpoint(\n",
    "    name=endpoint_name,\n",
    "    config={\n",
    "        \"served_entities\": [{\n",
    "                \"name\": f\"{endpoint_name}-{model_version}\",\n",
    "                \"entity_name\": model_name,\n",
    "                \"entity_version\": model_version,\n",
    "                \"type\": \"UC_MODEL\",\n",
    "                \"workload_size\": \"Small\",\n",
    "                \"scale_to_zero_enabled\": True\n",
    "        }]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cd1328b-c6c0-4b31-af14-ab1c484362aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check the ndpoint created.\n",
    "\n",
    "In the config, state is not ready.\n",
    "\n",
    "The config_update is in progress.\n",
    "\n",
    "Let's check the serving menu to verify the new model has been correctly created and is currently in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fde4eeaa-1276-47f2-88f4-4dfb631f4674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoints = mlflow_client.list_endpoints()\n",
    "endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b7c5be-7812-4b0a-addb-c6dce4c04ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7341769779003061,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Create_chain_0",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
