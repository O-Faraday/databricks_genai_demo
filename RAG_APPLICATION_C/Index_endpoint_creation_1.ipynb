{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a903136a-ed1e-4fe5-a223-7a1d2690dbfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Vector Search Endpoint and Index Creation\n",
    "\n",
    "In this notebook, we will create a Databricks Vector Search endpoint and index to enable semantic search over our document collection.\n",
    "\n",
    "## What this notebook does:\n",
    "1. Creates a Vector Search endpoint (compute infrastructure for vector operations)\n",
    "2. Enables Change Data Feed on our source table for incremental updates\n",
    "3. Creates a Delta Sync Vector Search Index that automatically embeds and indexes our documents\n",
    "\n",
    "This index will be used by our RAG chain to retrieve relevant document chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "install_packages_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install Required Packages\n",
    "\n",
    "Install the necessary libraries:\n",
    "- `databricks-vectorsearch`: Client library for managing Vector Search endpoints and indexes\n",
    "- `langchain`: Framework for building applications with LLMs (used for integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb638d2a-bf18-427e-8e6d-7d1556abe353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet -U langchain==0.3.25 databricks-vectorsearch==0.60 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b66af22e-8a07-48d0-b47e-de2eba0c4992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Restart Python kernel to load newly installed packages\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "config_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Unity Catalog Configuration\n",
    "\n",
    "Load the catalog and schema configuration to ensure we're working in the correct namespace.\n",
    "This configuration is shared across all notebooks in the project for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871d9a4d-8e47-427a-ab4c-487622328136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../_config/config_unity_catalog\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f131602-df21-4f8f-a139-05202ce4768d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1- Helper Functions for Vector Search Management\n",
    "\n",
    "These utility functions help us:\n",
    "- Check if endpoints and indexes already exist (avoid recreation)\n",
    "- Wait for asynchronous operations to complete\n",
    "- Handle rate limiting and error conditions gracefully\n",
    "- Provide clear status updates during long-running operations\n",
    "\n",
    "Vector Search endpoints and indexes are created asynchronously, so we need polling logic to wait for them to be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489c74c9-28dd-4b48-a1a1-d59df925c444",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def endpoint_exists(vsc, vs_endpoint_name):\n",
    "    \"\"\"\n",
    "    Check if a Vector Search endpoint already exists.\n",
    "    \n",
    "    This prevents attempting to recreate an existing endpoint, which would fail.\n",
    "    \n",
    "    Args:\n",
    "        vsc: VectorSearchClient instance\n",
    "        vs_endpoint_name: Name of the endpoint to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if endpoint exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return vs_endpoint_name in [e['name'] for e in vsc.list_endpoints().get('endpoints', [])]\n",
    "    except Exception as e:\n",
    "        # Handle temporary rate limiting issues\n",
    "        if \"REQUEST_LIMIT_EXCEEDED\" in str(e):\n",
    "            print(\"WARN: couldn't get endpoint status due to REQUEST_LIMIT_EXCEEDED error. The demo will assume it exists\")\n",
    "            return True\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "def wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name, n_attempts=10):\n",
    "    \"\"\"\n",
    "    Wait for a Vector Search endpoint to reach ONLINE status.\n",
    "    \n",
    "    Endpoint creation is asynchronous and can take several minutes.\n",
    "    This function polls the endpoint status until it's ready or times out.\n",
    "    \n",
    "    Args:\n",
    "        vsc: VectorSearchClient instance\n",
    "        vs_endpoint_name: Name of the endpoint\n",
    "        n_attempts: Maximum number of polling attempts (default: 10)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Endpoint details when ready\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If endpoint fails to become ready within timeout\n",
    "    \"\"\"\n",
    "    sleep_time = 100  # Wait 100 seconds between checks\n",
    "\n",
    "    for i in range(n_attempts):\n",
    "        try:\n",
    "            endpoint = vsc.get_endpoint(vs_endpoint_name)\n",
    "        except Exception as e:\n",
    "            # Handle temporary rate limiting issues\n",
    "            if \"REQUEST_LIMIT_EXCEEDED\" in str(e):\n",
    "                print(\"WARN: couldn't get endpoint status due to REQUEST_LIMIT_EXCEEDED error. Please manually check your endpoint status\")\n",
    "                return\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        # Get the current status of the endpoint\n",
    "        status = endpoint.get(\"endpoint_status\", endpoint.get(\"status\"))[\"state\"].upper()\n",
    "        \n",
    "        if \"ONLINE\" in status:\n",
    "            return endpoint\n",
    "        elif \"PROVISIONING\" in status or i < 6:\n",
    "            # Print status updates periodically\n",
    "            if i % 20 == 0: \n",
    "                print(f\"Waiting for endpoint to be ready, this can take a few min... {endpoint}\")\n",
    "            time.sleep(sleep_time)\n",
    "        else:\n",
    "            raise Exception(f'''Error with the endpoint {vs_endpoint_name}. - this shouldn't happen: {endpoint}.\\n Please delete it and re-run the previous cell: vsc.delete_endpoint(\"{vs_endpoint_name}\")''')\n",
    "\n",
    "    raise Exception(f\"Timeout, your endpoint isn't ready yet: {vsc.get_endpoint(vs_endpoint_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6320b051-df63-4838-a3e2-35e1c2d602aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def index_exists(vsc, vs_endpoint_name, vs_index_full_name):\n",
    "    \"\"\"\n",
    "    Check if a Vector Search index already exists.\n",
    "    \n",
    "    Args:\n",
    "        vsc: VectorSearchClient instance\n",
    "        vs_endpoint_name: Name of the endpoint hosting the index\n",
    "        vs_index_full_name: Full name of the index (catalog.schema.index_name)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if index exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vsc.get_index(vs_endpoint_name, vs_index_full_name).describe()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if 'RESOURCE_DOES_NOT_EXIST' not in str(e):\n",
    "            print(f'Unexpected error describing the index. This could be a permission issue.')\n",
    "            raise e\n",
    "    return False\n",
    "    \n",
    "def wait_for_index_to_be_ready(vsc, vs_endpoint_name, vs_index_name, n_attempts=10):\n",
    "    \"\"\"\n",
    "    Wait for a Vector Search index to reach ONLINE status.\n",
    "    \n",
    "    Index creation involves:\n",
    "    - Setting up the DLT pipeline\n",
    "    - Processing all source documents\n",
    "    - Generating embeddings for each chunk\n",
    "    - Building the vector index\n",
    "    \n",
    "    This can take several minutes for large document collections.\n",
    "    \n",
    "    Args:\n",
    "        vsc: VectorSearchClient instance\n",
    "        vs_endpoint_name: Name of the endpoint\n",
    "        vs_index_name: Full name of the index\n",
    "        n_attempts: Maximum number of polling attempts (default: 10)\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If index fails to become ready within timeout\n",
    "    \"\"\"\n",
    "    for i in range(n_attempts):\n",
    "        idx = vsc.get_index(vs_endpoint_name, vs_index_name).describe()\n",
    "        index_status = idx.get('status', idx.get('index_status', {}))\n",
    "        status = index_status.get('detailed_state', index_status.get('status', 'UNKNOWN')).upper()\n",
    "        url = index_status.get('index_url', index_status.get('url', 'UNKNOWN'))\n",
    "        \n",
    "        if \"ONLINE\" in status:\n",
    "            return\n",
    "        if \"UNKNOWN\" in status:\n",
    "            print(f\"Can't get the status - will assume index is ready {idx} - url: {url}\")\n",
    "            return\n",
    "        elif \"PROVISIONING\" in status:\n",
    "            # Print status updates periodically\n",
    "            if i % 40 == 0: \n",
    "                print(f\"Waiting for index to be ready, this can take a few min... {index_status} - pipeline url:{url}\")\n",
    "            time.sleep(100)\n",
    "        else:\n",
    "            raise Exception(f'''Error with the index - this shouldn't happen. DLT pipeline might have been killed.\\n Please delete it and re-run the previous cell: vsc.delete_index(\"{vs_index_name}\", \"{vs_endpoint_name}\") \\nIndex details: {idx}''')\n",
    "    \n",
    "    raise Exception(f\"Timeout, your index isn't ready yet: {vsc.get_index(vs_index_name, vs_endpoint_name)}\")\n",
    "\n",
    "def wait_for_model_serving_endpoint_to_be_ready(ep_name):\n",
    "    \"\"\"\n",
    "    Wait for a Model Serving endpoint to be ready.\n",
    "    \n",
    "    This function is used when deploying models to Databricks Model Serving.\n",
    "    It polls the endpoint status until deployment is complete.\n",
    "    \n",
    "    Args:\n",
    "        ep_name: Name of the serving endpoint\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If endpoint fails to become ready within timeout\n",
    "    \"\"\"\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate\n",
    "    import time\n",
    "\n",
    "    # Initialize Workspace Client\n",
    "    w = WorkspaceClient()\n",
    "    state = \"\"\n",
    "    \n",
    "    for i in range(200):\n",
    "        state = w.serving_endpoints.get(ep_name).state\n",
    "        if state.config_update == EndpointStateConfigUpdate.IN_PROGRESS:\n",
    "            if i % 40 == 0:\n",
    "                print(f\"Waiting for endpoint to deploy {ep_name}. Current state: {state}\")\n",
    "            time.sleep(10)\n",
    "        elif state.ready == EndpointStateReady.READY:\n",
    "            print('Endpoint ready.')\n",
    "            return\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    raise Exception(f\"Couldn't start the endpoint, timeout, please check your endpoint for more details: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "init_client_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2- Initialize Vector Search Client and Configuration\n",
    "\n",
    "Define the key configuration parameters:\n",
    "- **VECTOR_SEARCH_ENDPOINT_NAME**: Name of the endpoint that will host our indexes\n",
    "- **DOCUMENT_TABLE_NAME**: Source Delta table containing our document chunks\n",
    "\n",
    "The VectorSearchClient handles all interactions with the Vector Search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58c67ef1-ce27-4c64-a047-f93f125e0749",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Configuration\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"pdf_document_vs_endpoint\"\n",
    "DOCUMENT_TABLE_NAME = \"pdf_document_raw\"  # \n",
    "\n",
    "# Initialize Vector Search Client\n",
    "vsc = VectorSearchClient()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "create_endpoint_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3- Create Vector Search Endpoint\n",
    "\n",
    "A Vector Search endpoint provides the compute infrastructure for:\n",
    "- Hosting vector indexes\n",
    "- Processing search queries\n",
    "- Managing embeddings\n",
    "\n",
    "**Endpoint Types:**\n",
    "- **STANDARD**: Suitable for most production workloads (used here)\n",
    "- **OPTIMIZED**: For high-throughput, low-latency requirements\n",
    "\n",
    "The endpoint is created only if it doesn't already exist, then we wait for it to be ONLINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "226f36ae-d285-489b-a306-7e6e04f8d567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create endpoint if it doesn't exist\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type=\"STANDARD\")\n",
    "\n",
    "    # Wait for endpoint to be ready (can take several minutes)\n",
    "    wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "    print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.\")\n",
    "else:\n",
    "    print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "enable_cdf_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4- Enable Change Data Feed on Source Table\n",
    "\n",
    "**Change Data Feed (CDF)** is a Delta Lake feature that tracks row-level changes to a table.\n",
    "\n",
    "For Vector Search Delta Sync indexes, CDF is **required** because:\n",
    "- It enables incremental updates to the index\n",
    "- Only new/modified documents are re-embedded\n",
    "- Deleted documents are removed from the index\n",
    "- This makes index synchronization efficient\n",
    "\n",
    "Without CDF, the entire table would need to be reprocessed on every sync.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada55885-413a-4a61-a5c5-323e5533e9c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable Change Data Feed on the source table\n",
    "spark.sql(\n",
    "    f\"ALTER TABLE {DOCUMENT_TABLE_NAME} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "create_index_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5- Create Delta Sync Vector Search Index\n",
    "\n",
    "This is the core step where we create the vector search index.\n",
    "\n",
    "### What happens during index creation:\n",
    "1. A DLT (Delta Live Tables) pipeline is automatically created\n",
    "2. The pipeline reads data from the source Delta table\n",
    "3. Each document chunk is sent to the embedding model endpoint\n",
    "4. Embeddings are generated and stored in the vector index\n",
    "5. The index is optimized for similarity search\n",
    "\n",
    "### Key Parameters:\n",
    "- **endpoint_name**: The Vector Search endpoint hosting this index\n",
    "- **index_name**: Full name of the index (catalog.schema.index_name)\n",
    "- **source_table_name**: Delta table containing the documents\n",
    "- **pipeline_type**: \"TRIGGERED\" means manual sync, \"CONTINUOUS\" means automatic\n",
    "- **primary_key**: Unique identifier column (typically \"id\")\n",
    "- **embedding_source_column**: Column containing the text to embed\n",
    "- **embedding_model_endpoint_name**: Databricks Foundation Model endpoint for embeddings\n",
    "\n",
    "### Sync Behavior:\n",
    "- If index exists: Triggers a sync to update with new data\n",
    "- If index doesn't exist: Creates it and performs initial embedding\n",
    "\n",
    "**Note**: Initial index creation can take 10-30 minutes depending on document volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f46287cc-ba09-415a-b237-c15be481277d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import databricks.sdk.service.catalog as c\n",
    "\n",
    "# Construct full table names\n",
    "source_table_fullname = f\"{catalog}.{schema}.{DOCUMENT_TABLE_NAME}\"\n",
    "vs_index_fullname = f\"{catalog}.{schema}.{DOCUMENT_TABLE_NAME}_vs_index\"\n",
    "\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "    print(f\"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "    try:\n",
    "        vsc.create_delta_sync_index(\n",
    "            endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "            index_name=vs_index_fullname,\n",
    "            source_table_name=source_table_fullname,\n",
    "            pipeline_type=\"TRIGGERED\",  # Manual sync (use \"CONTINUOUS\" for auto-sync)\n",
    "            primary_key=\"id\",  # Unique identifier for each document chunk\n",
    "            embedding_source_column='content',  # Column containing the text to embed\n",
    "            embedding_model_endpoint_name='databricks-gte-large-en',  # Embedding model endpoint\n",
    "            columns_to_sync=[\"content\", \"source_name\"] \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    # Wait for index to be ready and all embeddings to be created\n",
    "    wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "else:\n",
    "    # Index already exists - trigger a sync to update with any new data\n",
    "    print(f\"Index {vs_index_fullname} already exists. Triggering sync...\")\n",
    "    wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "    vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).sync()\n",
    "\n",
    "print(f\"Index {vs_index_fullname} on table {source_table_fullname} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "completion_header",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Next Steps:\n",
    "- Use this index in your RAG chain for document retrieval\n",
    "- Test semantic search queries\n",
    "\n",
    "### Important Resources:\n",
    "- **Index Name**: `{vs_index_fullname}`\n",
    "- **Endpoint Name**: `{VECTOR_SEARCH_ENDPOINT_NAME}`\n",
    "- **Source Table**: `{source_table_fullname}`\n",
    "\n",
    "These values will be used in the RAG chain configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a72b48c0-87ff-4418-9f64-d80691eb7be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Index_endpoint_creation_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
